---
title: Assignment 12 - Generative Pre-Trained Transformers (GPTs) Part 1
toc_sticky: true 
toc_h_max: 1
layout: problemset
---

# Learning Objectives

{% capture content %}
* Learn about sequence prediction for text
* Learn about different types of tokenization
* Bigram model as a stepping stone to GPTs
* Understand and build a self-attention block
{% endcapture %}
{% include learning_objectives.html content=content %}

TODO